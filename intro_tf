import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = keras.datasets.fashion_mnist # declaring a variable for the dataset
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() # seperating the dataset for learning
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # from 0 to 9 corressponding names for item number values
print(train_images.shape) # shape of data(it has 60000 28x28 images)
print(train_images.shape) # shape of data(it has 60000 28x28 images)

# shows any chosen image(by index) from chosen data
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

# the data needs to be preprocessed, so it can be coherent
# so we divide the data uniformly for uniformity XD
train_images = train_images / 255.0
test_images = test_images / 255.0

# veiw of first 25 images in training data with corresponding class
# to make sure all is well
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

# now the basis of the neural network gets built
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),# changes 28x28 p into 1d array
    keras.layers.Dense(128, activation='relu'), # first layer
    keras.layers.Dense(10) # output node should equal input of classes
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# now its time to actually train the model by "feeding" it
model.fit(train_images, train_labels, epochs=10)

# now the accuracy of the model is evaluated
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)

# with the model trained predictions can now be made
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()]) 
# i dont know why for now but a softmax layer was added for "easier"
# interpretion

predictions = probability_model.predict(test_images)
# the variable probability is given to an array of the models "confidence"
# for the test_images

print(np.argmax(predictions[0])) #np.argmax is added to show max confidence

# the actuality can be checked by simply indexing the test_label we want to check
print(test_labels[0])


def veiw():
    i = int(input("what index do you want to veiw "))
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel("prediction = "+ class_names[train_labels[i]])
    plt.show()
    
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_images[i])
    plt.xlabel("actuality = "+ class_names[test_labels[i]])
    plt.show()
    
    # actuality shows if the prediction is correct

veiw()
